{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import  Sequential\n",
    "from keras.layers import Conv2D,Flatten,MaxPooling2D,Dense,Dropout,BatchNormalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory Naming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder = 'dataset'\n",
    "\n",
    "sub_folders = os.listdir(main_folder)\n",
    "\n",
    "for sub_folder in sub_folders:\n",
    "    sub_folder_Path = os.path.join(main_folder,sub_folder)\n",
    "\n",
    "    word = sub_folder.split()\n",
    "\n",
    "    one_word = '_'.join(word)\n",
    "\n",
    "    os.rename(sub_folder_Path,os.path.join(main_folder,one_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augumentation and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5851 images belonging to 102 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "\n",
    "dataset_generator = dataset.flow_from_directory(\n",
    "    'dataset',\n",
    "    target_size=(150,150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(256,(3,3),input_shape=(150,150,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(256,(3,3),input_shape=(150,150,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=256,activation='relu'))\n",
    "model.add(Dense(units=102,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "conv_base = VGG16(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(150,150,3)\n",
    ")\n",
    "conv_base.trainable = False\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(conv_base)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=256,activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=256,activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=102,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "30/30 [==============================] - 51s 2s/step - loss: 4.7725 - accuracy: 0.0156\n",
      "Epoch 2/100\n",
      "20/30 [===================>..........] - ETA: 16s - loss: 4.6234 - accuracy: 0.0109"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\ML Python VsCode\\Yoga_Pose_Classification\\venv\\Lib\\site-packages\\PIL\\Image.py:981: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 52s 2s/step - loss: 4.6137 - accuracy: 0.0146\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 50s 2s/step - loss: 4.5496 - accuracy: 0.0271\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 50s 2s/step - loss: 4.4571 - accuracy: 0.0335\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 50s 2s/step - loss: 4.3636 - accuracy: 0.0469\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 55s 2s/step - loss: 4.2338 - accuracy: 0.0615\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 51s 2s/step - loss: 4.1229 - accuracy: 0.0594\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 49s 2s/step - loss: 3.9786 - accuracy: 0.0833\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 54s 2s/step - loss: 3.8748 - accuracy: 0.1042\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 51s 2s/step - loss: 3.7647 - accuracy: 0.1156\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 49s 2s/step - loss: 3.7459 - accuracy: 0.1010\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 52s 2s/step - loss: 3.6609 - accuracy: 0.1031\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 55s 2s/step - loss: 3.6496 - accuracy: 0.1052\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 49s 2s/step - loss: 3.5434 - accuracy: 0.1372\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 49s 2s/step - loss: 3.6188 - accuracy: 0.1260\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 48s 2s/step - loss: 3.4910 - accuracy: 0.1333\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 49s 2s/step - loss: 3.4602 - accuracy: 0.1385\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 49s 2s/step - loss: 3.4236 - accuracy: 0.1424\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 50s 2s/step - loss: 3.4080 - accuracy: 0.1417\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 50s 2s/step - loss: 3.3682 - accuracy: 0.1729\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 51s 2s/step - loss: 3.3045 - accuracy: 0.1500\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 49s 2s/step - loss: 3.2887 - accuracy: 0.1708\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 50s 2s/step - loss: 3.2406 - accuracy: 0.1615\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 49s 2s/step - loss: 3.3030 - accuracy: 0.1490\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 47s 2s/step - loss: 3.2570 - accuracy: 0.1677\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 48s 2s/step - loss: 3.2639 - accuracy: 0.1740\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 48s 2s/step - loss: 3.2089 - accuracy: 0.1792\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 48s 2s/step - loss: 3.1752 - accuracy: 0.1771\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 48s 2s/step - loss: 3.2852 - accuracy: 0.1594\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 48s 2s/step - loss: 3.1177 - accuracy: 0.1927\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 48s 2s/step - loss: 3.1489 - accuracy: 0.1750\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 46s 2s/step - loss: 3.0429 - accuracy: 0.2021\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 49s 2s/step - loss: 3.0818 - accuracy: 0.1885\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 49s 2s/step - loss: 3.0534 - accuracy: 0.1895\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 48s 2s/step - loss: 3.2154 - accuracy: 0.1854\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 47s 2s/step - loss: 3.0809 - accuracy: 0.1927\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 48s 2s/step - loss: 3.0573 - accuracy: 0.1896\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 49s 2s/step - loss: 3.0792 - accuracy: 0.1948\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 52s 2s/step - loss: 3.0659 - accuracy: 0.1885\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 50s 2s/step - loss: 3.0580 - accuracy: 0.1906\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 48s 2s/step - loss: 3.0332 - accuracy: 0.2115\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 49s 2s/step - loss: 2.9396 - accuracy: 0.2198\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 50s 2s/step - loss: 2.9641 - accuracy: 0.2271\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 49s 2s/step - loss: 3.1244 - accuracy: 0.2073\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 49s 2s/step - loss: 3.0771 - accuracy: 0.2094\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 50s 2s/step - loss: 2.9387 - accuracy: 0.2146\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 48s 2s/step - loss: 3.0078 - accuracy: 0.2115\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 48s 2s/step - loss: 2.9843 - accuracy: 0.2250\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 50s 2s/step - loss: 3.0701 - accuracy: 0.1854\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 50s 2s/step - loss: 2.9836 - accuracy: 0.2042\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 48s 2s/step - loss: 2.9373 - accuracy: 0.2168\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 47s 2s/step - loss: 2.9137 - accuracy: 0.2177\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 47s 2s/step - loss: 2.9852 - accuracy: 0.2021\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 48s 2s/step - loss: 3.0025 - accuracy: 0.2156\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 51s 2s/step - loss: 2.9386 - accuracy: 0.2062\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 50s 2s/step - loss: 2.8380 - accuracy: 0.2417\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 50s 2s/step - loss: 2.8811 - accuracy: 0.2354\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 48s 2s/step - loss: 2.9213 - accuracy: 0.2344\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 48s 2s/step - loss: 2.9251 - accuracy: 0.2542\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 48s 2s/step - loss: 2.9265 - accuracy: 0.2260\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 48s 2s/step - loss: 2.9298 - accuracy: 0.2198\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 49s 2s/step - loss: 2.8530 - accuracy: 0.2365\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 54s 2s/step - loss: 2.8682 - accuracy: 0.2396\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 46s 2s/step - loss: 2.9089 - accuracy: 0.2250\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 45s 2s/step - loss: 2.9126 - accuracy: 0.2083\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 45s 1s/step - loss: 2.8686 - accuracy: 0.2251\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 46s 2s/step - loss: 2.8536 - accuracy: 0.2555\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 46s 2s/step - loss: 2.8495 - accuracy: 0.2304\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 48s 2s/step - loss: 2.8698 - accuracy: 0.2281\n",
      "Epoch 70/100\n",
      "15/30 [==============>...............] - ETA: 23s - loss: 2.8243 - accuracy: 0.2292"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset_generator,epochs=100,steps_per_epoch=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
